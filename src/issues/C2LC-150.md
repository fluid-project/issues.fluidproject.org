---json
{
  "title": "C2LC-150",
  "summary": "Music Band",
  "tags": "C2LC",
  "project": {
    "key": "C2LC",
    "title": "Coding to Learn and Create"
  },
  "type": "New Feature",
  "status": "Won't Fix",
  "date": "2020-01-09T14:16:19.079-0500",
  "updated": "2024-05-03T11:40:09.953-0400",
  "versions": [],
  "fixVersions": [
    "Future Work"
  ],
  "components": [],
  "environment": null,
  "issueLinks": [
    {
      "type": "Related to",
      "url": "/browse/C2LC-181/",
      "key": "C2LC-181",
      "summary": "Bridges Coding Environment Brainstorm"
    },
    {
      "type": "Related to",
      "url": "/browse/C2LC-138/",
      "key": "C2LC-138"
    },
    {
      "type": "Related to",
      "url": "/browse/C2LC-181/",
      "key": "C2LC-181"
    }
  ],
  "attachments": [],
  "comments": []
}
---
An AR interface should be able to pick up multiple participants and each one of them should be able to pick their tools/instruments and discern themselves on the screen&#x20;

Description from source:

Letting users collaborate, pick instruments (different colours), possibly show musical notes emanating from their bodies\
If a student is engaged in the activity and another enters the room there should be some interaction that lets the new user pick an instrument and make it clear that both users are now playing music together - Learners were not able to select their own colours or instruments in BodySynth and the camera would shift focus from one person to another so music could not be played concurrently by several users

We could do design and dev experiments

        